{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, read some wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First, the imports\n",
    "import os\n",
    "import datetime as dt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "np.random.seed(19760812)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We read a file of wind data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read file 'mast.txt'\n",
    "ipath = os.path.join('Datos', 'mast.txt')\n",
    "\n",
    "def dateparse(date, time):\n",
    "    YY = 2000 + int(date[:2])\n",
    "    MM = int(date[2:4])\n",
    "    DD = int(date[4:])\n",
    "    hh = int(time[:2])\n",
    "    mm = int(time[2:])\n",
    "    \n",
    "    return dt.datetime(YY, MM, DD, hh, mm, 0)\n",
    "    \n",
    "\n",
    "cols = ['Date', 'time', 'wspd', 'wspd_max', 'wdir',\n",
    "        'x1', 'x2', 'x3', 'x4', 'x5', \n",
    "        'wspd_std']\n",
    "wind = pd.read_csv(ipath, sep = \"\\s*\", names = cols, \n",
    "                   parse_dates = {'Timestamp': [0, 1]}, index_col = 0,\n",
    "                   date_parser = dateparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We read a second file of simulated environmental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read file 'model.txt'\n",
    "ipath = os.path.join('Datos', 'model.txt')\n",
    "\n",
    "model = pd.read_csv(ipath, sep = \"\\s*\", skiprows = 3,\n",
    "                    parse_dates = {'Timestamp': [0, 1]}, index_col = 'Timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in ['x1','x2','x3','x4','x5']: # remove unnecesary columns\n",
    "    _ = wind.pop(c)\n",
    "wind.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind['Timestamp'] = wind.index\n",
    "print(wind['Timestamp'].diff().min())\n",
    "del wind['Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model['Timestamp'] = model.index\n",
    "print(model['Timestamp'].diff().min())\n",
    "del model['Timestamp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data with a time frequency of 10 minutes (`wind`) vs the second file data (`model`) with a time frequency of 1 hour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parenthetical remark: `axis` 101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some occasions we will find a *keyword* called `axis`. Let's see in a moment how it works in `pandas` to try to avoid some issues:\n",
    "\n",
    "## Posibilities\n",
    "\n",
    "* axis = 0 (acts over rows)\n",
    "* axis = 1 (acts over columns)\n",
    "* <span style=\"color:#888\">axis = 2 (only for `Panel`)</span>\n",
    "\n",
    "![](imgs/DF_Rows_Columns.jpg)\n",
    "(source: http://stackoverflow.com/a/25774395/5216568).\n",
    "\n",
    "<br>\n",
    "<div class=\"alert alert-info\">\n",
    "<p><b>Flashcard:</b></p> \n",
    "<p><a href=\"https://www.reddit.com/r/pystats/comments/2z0xbc/pandas_axis0_or_axis1_not_intuitive_for_you_use/cpev7x9\">Easiest way to remember is that \"1\" looks like a column!</a></p>\n",
    "<p><b>Other options:</b></p> \n",
    "<p>One option would be to use `axis = 'index'` (similar to `axis = 0`) or `axis = 'columns'` (similar to `axis = 1`) for `DataFrame`s. In the case of `Panel`s we would have `items`, `minor`, `major` (similar to options 0, 1 or 2).</p>.\n",
    "<p>For a `DataFrame`s you could also use `index = 'rows'`, I think it is more evident than `'index'` but I don't recommend it as it is not documented.</p>\n",
    "<p>Also, using `'index'`, `'rows'`, `'columns'`,..., can be confuse as in a lot of places we will find keywordscalled like this.</p>.\n",
    "</div>\n",
    "\n",
    "But, what is the meaning of 'acts over rows/columns'. Let's see some simple examples to check if it is clear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.array([[1, 10], [2, 20], [3,30]]), columns = ['A', 'B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't use the `axis` keyword explicitly, by default, operations are over rows (`axis = 0`), i.e., it uses all the elements of a column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The previous example would be similar to\n",
    "df.sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to obtain the result on each row, i.e., all the elements of all columns in a row, we should add `axis = 1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df < 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df < 10).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(df < 10).all(axis = 'columns') # instead of axis = 1 we use axis = 'columns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test operations of a DatFrame using axis = 0, 1, 'index', rows', columns'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you have a clear idea now about how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging/combining `pandas` data structures\n",
    "\n",
    "What we will [see now is not evident](http://pandas.pydata.org/pandas-docs/stable/merging.html) and, in some cases, it is convenient to know how [relational algebral](https://en.wikipedia.org/wiki/Relational_algebra) works to better understand what it is happening.\n",
    "\n",
    "## Combining data using `concat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = pd.concat([wind, model], axis = 0, join = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new.loc['2014/01/01 00:00':'2014/01/01 02:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/merging_concat_basic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new = pd.concat([wind, model], axis = 1, join = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new.loc['2014/01/01 00:00':'2014/01/01 02:00']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concat` allows us to 'merge' `pandas` data structures using rows and columns. \n",
    "\n",
    "What we have seen is not clear!!!??? And you didn't asked!!!???\n",
    "\n",
    "Let's see a simpler example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(np.random.randn(10,2), \n",
    "                   columns = ['A', 'B'], \n",
    "                   index = np.arange(10))\n",
    "df2 = pd.DataFrame(np.random.randn(4,3), \n",
    "                   columns = ['A', 'B', 'C'], \n",
    "                   index = np.arange(8, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = pd.concat([df1, df2], axis = 0, join = 'inner')\n",
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new = pd.concat([df1, df2], axis = 1, join = 'inner')\n",
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, I use this last option with different column names as it is what I want to do..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenating using the `append` method\n",
    "\n",
    "We can get something similar to the previous examples using the `append` method of the data structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind.append(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, this is not what I want to do. What I want to do is a merge with some logics and to do so we could use `pd.merge`...\n",
    "\n",
    "## Using `pd.merge` as in a SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(wind, model, left_index = True, right_index = True, how = 'inner').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(pd.merge(wind, model, left_index = True, right_index = True, how = 'inner') == \n",
    " pd.concat([wind, model], axis = 1, join = 'inner')).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine we want to merge two `DataFrame`s using columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(\n",
    "    np.array([\n",
    "        np.arange(1, 11),\n",
    "        np.random.choice([1,2,3], size = 10),\n",
    "        np.arange(1, 11) * 10\n",
    "    ]).T,\n",
    "    columns = ['A', 'col', 'B']\n",
    ")\n",
    "df2 = pd.DataFrame(\n",
    "    np.array([\n",
    "        np.arange(11, 21),\n",
    "        np.random.choice([1,2,3], size = 10),\n",
    "        np.arange(1, 11) * 100\n",
    "    ]).T,\n",
    "    columns = ['A', 'col', 'B']\n",
    ")\n",
    "display(df1)\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.merge(df1, df2, on = ['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Play with it with pd.merge keywords to become more comfortable with it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining using the `join` method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More about the same. The `join` method helps us to combine `pandas` data structures. Some quick examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind.join(model).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.join(wind).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joinA  = wind.join(model, how = 'inner') \n",
    "joinB = model.join(wind, how = 'inner').loc[:,joinA.columns]\n",
    "(joinA == joinB).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping\n",
    "\n",
    "We can group information of our data structures in a simple way using the `groupby` method. In general, here we follow a strategy of split-apply-combine. What we do is, first separate the initial dataset in groups of interest, over each group we apply some calculations and, finally, the results obtained on each group is combined in a new data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind['month'] = wind.index.month\n",
    "wind.iloc[[0, 1000, 10000, 30000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind.groupby(by = 'month').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind.groupby(by = [wind.index.year, 'month']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del wind['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Play grouping \n",
    "# (obtain daily mean wind speed, \n",
    "# mean wind speed on Tuesdays when wind direction is between 300º and 360º,...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what `groupby` returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = wind.groupby(by=wind.index.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "info = inspect.getmembers(grouped, predicate=inspect.ismethod)\n",
    "\n",
    "for stuff in info:\n",
    "    print(stuff[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.ngroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped.get_group(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas.core.groupby.DataFrameGroupBy` is like a dict with superpowers!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping/transforming our data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<p>Most of this section has been extracted from <a href=\"https://nikolaygrozev.wordpress.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/\">excellent article</a>\n",
    "<em>Reshaping in Pandas – Pivot, Pivot-Table, Stack and Unstack explained with Pictures</em> by <b>Nikolay Grozev</b>.</p>\n",
    "<p>Kudos to Nikolay.</p>\n",
    "<p>Kudos to me because a followed the <a href=\"https://en.wikipedia.org/wiki/Don't_repeat_yourself\">DRY</a> and <a href=\"https://en.wikipedia.org/wiki/KISS_principle\">KISS</a> principles.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping allows us to change our data structure in a new one to perform new analyses on the new recombined data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Pivot`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a new table derived from our initial data table. For instance, imagine I want to obtain monthly mean wind speed on each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wind['year'] = wind.index.year\n",
    "wind['month'] = wind.index.month\n",
    "tmp = wind.groupby(by = ['year', 'month']).mean()\n",
    "del wind['year']\n",
    "del wind['month']\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp['year'] = tmp.index.get_level_values(0)\n",
    "tmp['month'] = tmp.index.get_level_values(1)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp.pivot(index = 'year', columns = 'month', values='wspd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the yearly mean wind speed \n",
    "# starting from tmp.pivot(index = 'year', columns = 'month', values='wspd')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivoting using several columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = wind.groupby(by = [wind.index.year, wind.index.month])\n",
    "tmp = tmp.agg({'wspd': np.mean, 'wspd_max': 'max'})\n",
    "tmp.reset_index(inplace = True)\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp.pivot(index = 'level_1', columns = 'level_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp.pivot(index = 'level_1', columns = 'level_0').columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we combine repeated indexes. For instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "table = OrderedDict((\n",
    "    (\"Item\", ['Item0', 'Item0', 'Item0', 'Item1']),\n",
    "    ('CType',['Gold', 'Bronze', 'Gold', 'Silver']),\n",
    "    ('USD',  ['1$', '2$', '3$', '4$']),\n",
    "    ('EU',   ['1€', '2€', '3€', '4€'])\n",
    "))\n",
    "df = pd.DataFrame(table)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/pivoting_simple_error.png)\n",
    "(source: https://nikolaygrozev.files.wordpress.com/2015/07/pivoting_simple_error.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted = df.pivot(index='Item', columns='CType', values='USD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `pivot_table` to the rescue to solve the previous error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The previous error can be solved using `pivot_table` that is more flexible than `pivot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table = OrderedDict((\n",
    "    (\"Item\", ['Item0', 'Item0', 'Item0', 'Item1']),\n",
    "    ('CType',['Gold', 'Bronze', 'Gold', 'Silver']),\n",
    "    ('USD',  [1, 2, 3, 4]),\n",
    "    ('EU',   [1.1, 2.2, 3.3, 4.4])\n",
    "))\n",
    "df = pd.DataFrame(table)\n",
    "pivoted = df.pivot_table(index='Item', columns='CType', values='USD', aggfunc=np.min)\n",
    "pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack and Unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see it briefly to maintain it simple. It involves the uses of `MultiIndex` that I want to avoid today.\n",
    "\n",
    "![](imgs/stack-unstack1.png)\n",
    "(source: https://nikolaygrozev.files.wordpress.com/2015/07/stack-unstack1.png)\n",
    "\n",
    "Docs for [stack](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.stack.html).\n",
    "\n",
    "Docs for [unstack](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.unstack.html).\n",
    "\n",
    "Recipes for [stack/unstack](http://pandas.pydata.org/pandas-docs/stable/reshaping.html#reshaping-by-stacking-and-unstacking)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
